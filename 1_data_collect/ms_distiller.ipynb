{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "a = f'https://distiller.com/profile/washeewashee/following'\n",
    "a = requests.get(a)\n",
    "a_soup = BeautifulSoup(a.text, \"lxml\")\n",
    "following_num = a_soup.select_one(\"#main-content > div > div.center-column > div > div.desktop-profile-nav > div > div.user-statistics > div.statistic.following-link > a > span\").get_text().split()[0]\n",
    "print(following_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "washeewashee 유저가 팔로잉한 유저\n",
      "추가 페이지가 없음 worldwhiskies95\n",
      "추가 페이지가 없음 LeeEvolved\n",
      "추가 페이지가 없음 BDanner\n",
      "추가 페이지가 없음 Jastrze3\n",
      "추가 페이지가 없음 mikael\n",
      "추가 페이지가 없음 whiskeylush\n",
      "추가 페이지가 없음 PBMichiganWolverine\n",
      "추가 페이지가 없음 Slainte-Mhath\n",
      "추가 페이지가 없음 Distiller\n",
      "추가 페이지가 없음 Evan-Haskill\n",
      "추가 페이지가 없음 scotch_trooper\n",
      "추가 페이지가 없음 Richard-ModernDrinking\n",
      "추가 페이지가 없음 Telex\n",
      "추가 페이지가 없음 Scott_E\n",
      "추가 페이지가 없음 The_Rev\n",
      "exelixi 유저가 팔로잉한 유저\n",
      "thewhiskeyjug 유저가 팔로잉한 유저\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    379\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m                 \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-915f38e9469c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;36m20\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfollowing_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0muser_page_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'https://distiller.com/profile/{i}/following'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0muser_page_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_page_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0muser_page_num_soup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_page_num\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lxml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0muser_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_page_soup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"div\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"name\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    540\u001b[0m         }\n\u001b[0;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m                 )\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    381\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1329\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1331\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1332\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1007\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1009\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1010\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1011\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    869\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python36\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    629\u001b[0m         \"\"\"\n\u001b[0;32m    630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\"}\n",
    "\n",
    "# page_url = f\"https://distiller.com/user_search\"\n",
    "# page = requests.get(page_url, headers=headers)\n",
    "heavy_members = ['cascode', 'pbmichiganwolverine', 'scott_e', 'ctbeck11', 'soonershrink', 'stephanie_moreno','washeewashee', 'exelixi', 'thewhiskeyjug', 'joeparkerpoe', 'leeevolved', 'slainte-mhath', 'doneeb', 'islay_emissary', 'richard-moderndrinking'] \n",
    "for i in heavy_members:\n",
    "    print(f'{i} 유저가 팔로잉한 유저')\n",
    "    user_page = f'https://distiller.com/profile/{i}/following'\n",
    "    user_page = requests.get(user_page, headers=headers)\n",
    "    if user_page.status_code == 200:\n",
    "        user_page_soup = BeautifulSoup(user_page.text, \"lxml\")\n",
    "        following_num = user_page_soup.select_one(\"#main-content > div > div.center-column > div > div.desktop-profile-nav > div > div.user-statistics > div.statistic.following-link > a > span\").get_text().split()[0]\n",
    "        if 20 >= int(following_num):\n",
    "            user_page_num = f'https://distiller.com/profile/{i}/following'\n",
    "            user_page_num = requests.get(user_page_num, headers=headers)\n",
    "            user_page_num_soup = BeautifulSoup(user_page_num.text, \"lxml\")\n",
    "            user_names = user_page_soup.find_all(\"div\", attrs={\"class\": \"name\"})\n",
    "            for k in user_names:\n",
    "                print(f'추가 페이지가 없음 {k.get_text()}')\n",
    "        else:\n",
    "            last_page = user_page_soup.select_one(\"#main-content > div > div.center-column > div > div.personal-content > div.profile-list > ul > div > div > nav > span.last > a\").attrs['href']\n",
    "            n = int(last_page.split('=')[1])\n",
    "            for j in range(1, n):\n",
    "                    user_page_num = f'https://distiller.com/profile/{i}/following?page={j}'\n",
    "                    user_page_num = requests.get(user_page_num, headers=headers)\n",
    "                    user_page_num_soup = BeautifulSoup(user_page_num.text, \"lxml\")\n",
    "                    user_names = user_page_soup.find_all(\"div\", attrs={\"class\": \"name\"})\n",
    "                    for k in user_names:\n",
    "                        print(f'{j}페이지의 {k.get_text()}')\n",
    "\n",
    "        # print(i, '가 팔로잉하는 유저 :',user_names)\n",
    "    else:\n",
    "        print(f'{i}는 {user_page.status_code}에러 입니다.')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_soup = BeautifulSoup(page.text, \"lxml\")\n",
    "    last_page = page_soup.find(\"em\", attrs=\"num_page\").get_text()\n",
    "    lastPage_num = re.sub(r'[^0-9]', '', last_page)\n",
    "    # print(lastPage_num)\n",
    "\n",
    "    results = []\n",
    "    for j in range(1, int(lastPage_num) + 1):\n",
    "        main_url = f\"https://news.daum.net/breakingnews/?page={j}&regDate={yesterDate}\"  # url 입력\n",
    "        res = requests.get(main_url, headers=headers)\n",
    "\n",
    "        if res.status_code == 200:\n",
    "            print(yesterDate, int(lastPage_num), '중', j, 'page', round(j / int(lastPage_num) * 100, 2), '%', main_url,\n",
    "                  'status:', res.status_code)\n",
    "            soup = BeautifulSoup(res.text, \"lxml\")  # soup으로 저장\n",
    "            main = soup.find(\"ul\", attrs={\"class\": \"list_news2 list_allnews\"})\n",
    "            news = main.find_all(\"strong\", attrs={\"class\": \"tit_thumb\"})\n",
    "            cnt = 0\n",
    "\n",
    "            for new in news:\n",
    "                urls = new.select_one(\"a\")[\"href\"]  # 페이지에 나와있는 뉴스 URL 변수 입력\n",
    "                # print(urls)\n",
    "                result = requests.get(urls, headers=headers)  # request 로 다시 개별 뉴스 접속\n",
    "\n",
    "                if result.status_code == 200:\n",
    "                    news_soup = BeautifulSoup(result.text, \"lxml\")\n",
    "                    # 뉴스 제목, 발행시간, 기사본문 저장\n",
    "                    news_name = news_soup.find(\"h3\", attrs={\"tit_view\"}).get_text().strip()\n",
    "                    pubdate = news_soup.find(\"span\", attrs={\"num_date\"}).get_text().strip()\n",
    "                    text = news_soup.find(\"div\", attrs={\"news_view\"}).get_text().strip()\n",
    "                    data_prep = preprocessing_articles(text)\n",
    "                    news_content = \"\".join(data_prep).strip()\n",
    "                    result_a = [news_name, pubdate, news_content, urls]\n",
    "                    results.append(result_a)\n",
    "                    cnt += 1\n",
    "\n",
    "                else:\n",
    "                    print(yesterDate, 'page : ', j, '번째 기사', 'error_code :', result.status_code, urls)\n",
    "                    pass\n",
    "\n",
    "        else:\n",
    "            print(yesterDate, 'page : ', j, 'error_code :', res.status_code, main_url)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# \n",
    "heavy_members = ['cascode'#, 'pbmichiganwolverine', 'scott_e', 'ctbeck11', 'soonershrink', 'stephanie_moreno','washeewashee', 'exelixi', 'thewhiskeyjug', 'joeparkerpoe', 'leeevolved', 'slainte-mhath', 'doneeb', 'islay_emissary', 'richard-moderndrinking'\n",
    "                 ]\n",
    "following_table = pd.DataFrame(data=[],  columns=heavy_members)\n",
    "followers_table = pd.DataFrame(data=[],  columns=heavy_members)\n",
    "sample_members = ['cascode'#, 'pbmichiganwolverine', 'scott_e', 'ctbeck11', 'soonershrink', 'stephanie_moreno','washeewashee', 'exelixi', 'thewhiskeyjug', 'joeparkerpoe', 'leeevolved', 'slainte-mhath', 'doneeb', 'islay_emissary', 'richard-moderndrinking'\n",
    "                  ]\n",
    "user_urls = ['/profile/cascode']\n",
    "\n",
    "for i in heavy_members:\n",
    "    following_members = []\n",
    "    followers = []\n",
    "\n",
    "    print(f'{i} 유저가 팔로잉한 유저')\n",
    "    following_page = f'https://distiller.com/profile/{i}/following'\n",
    "    following_page = requests.get(following_page)\n",
    "    if following_page.status_code == 200:\n",
    "        following_page_soup = BeautifulSoup(following_page.text, \"lxml\")\n",
    "        following_num = following_page_soup.select_one(\"#main-content > div > div.center-column > div > div.desktop-profile-nav > div > div.user-statistics > div.statistic.following-link > a > span\").get_text().split()[0]\n",
    "        if int(following_num) == 0:\n",
    "            pass\n",
    "        elif int(following_num) <= 20:\n",
    "            following_page_num = f'https://distiller.com/profile/{i}/following'\n",
    "            following_page_num = requests.get(following_page_num)\n",
    "            following_page_num_soup = BeautifulSoup(following_page_num.text, \"lxml\")\n",
    "            user_names = following_page_soup.find_all(\"div\", attrs={\"class\": \"name\"})\n",
    "            following_members += [name.get_text() for name in user_names]\n",
    "            \n",
    "            user_url = following_page_num_soup.find_all(\"li\", attrs={\"class\": \"user-list-item\"})  \n",
    "            user_urls.extend([url.find('a')['href'] for url in user_url])\n",
    "        else:\n",
    "            last_page = following_page_soup.select_one(\"#main-content > div > div.center-column > div > div.personal-content > div.profile-list > ul > div > div > nav > span.last > a\").attrs['href']\n",
    "            n = int(last_page.split('=')[1])\n",
    "            for j in range(1, n+1):\n",
    "                following_page_num = f'https://distiller.com/profile/{i}/following?page={j}'\n",
    "                following_page_num = requests.get(following_page_num)\n",
    "                following_page_num_soup = BeautifulSoup(following_page_num.text, \"lxml\")\n",
    "                user_names = following_page_num_soup.find_all(\"div\", attrs={\"class\": \"name\"})\n",
    "                following_members += [name.get_text() for name in user_names]\n",
    "                \n",
    "                user_url = following_page_num_soup.find_all(\"li\", attrs={\"class\": \"user-list-item\"})  \n",
    "                user_urls.extend([url.find('a')['href'] for url in user_url])\n",
    "    else:\n",
    "        print(f'{i}는 {following_page.status_code}에러 입니다.')\n",
    "\n",
    "    print(f'{i} 유저의 팔로워 유저')\n",
    "    followers_page = f'https://distiller.com/profile/{i}/followers'\n",
    "    followers_page = requests.get(followers_page)\n",
    "    if followers_page.status_code == 200:\n",
    "        followers_page_soup = BeautifulSoup(followers_page.text, \"lxml\")\n",
    "        followers_num = followers_page_soup.select_one(\"#main-content > div > div.center-column > div > div.desktop-profile-nav > div > div.user-statistics > div.statistic.followers-link > a > span\").get_text().split()[0]\n",
    "        if int(followers_num) == 0:\n",
    "            pass\n",
    "        elif int(followers_num) <= 20:\n",
    "            followers_page_num = f'https://distiller.com/profile/{i}/followers'\n",
    "            followers_page_num = requests.get(followers_page_num)\n",
    "            followers_page_num_soup = BeautifulSoup(followers_page_num.text, \"lxml\")\n",
    "            followers_names = followers_page_num_soup.find_all(\"div\", attrs={\"class\": \"name\"})\n",
    "            followers+=[name.get_text() for name in followers_names]\n",
    "            \n",
    "            user_url = following_page_num_soup.find_all(\"li\", attrs={\"class\": \"user-list-item\"})  \n",
    "            user_urls.extend([url.find('a')['href'] for url in user_url])\n",
    "        else:\n",
    "            last_page = followers_page_soup.select_one(\"#main-content > div > div.center-column > div > div.personal-content > div.profile-list > ul > div > div > nav > span.last > a\").attrs['href']\n",
    "            n = int(last_page.split('=')[1])\n",
    "            for j in range(1, n+1):\n",
    "                followers_page_num = f'https://distiller.com/profile/{i}/followers?page={j}'\n",
    "                followers_page_num = requests.get(followers_page_num)\n",
    "                followers_page_num_soup = BeautifulSoup(followers_page_num.text, \"lxml\")\n",
    "                followers_names = followers_page_num_soup.find_all(\"div\", attrs={\"class\": \"name\"})\n",
    "                followers+=[name.get_text() for name in followers_names]\n",
    "                \n",
    "                user_url = following_page_num_soup.find_all(\"li\", attrs={\"class\": \"user-list-item\"})  \n",
    "                user_urls.extend([url.find('a')['href'] for url in user_url])\n",
    "    else:\n",
    "        print(f'{i}는 {followers_page.status_code}에러 입니다.')\n",
    "        \n",
    "    print('following_members '+str(len(following_members))+'명')\n",
    "    print('followers '+str(len(followers))+'명')\n",
    "\n",
    "    following_table[i] = pd.Series(following_members)\n",
    "    followers_table[i] = pd.Series(followers)\n",
    "\n",
    "    sample_members.extend(following_members)\n",
    "    sample_members.extend(followers)\n",
    "    \n",
    "print('heavy_members '+str(len(heavy_members))+'명')\n",
    "print('sample_members '+str(set(sample_members))+'명')\n",
    "\n",
    "following_table.to_csv('C:/Users/codnj/python_vscode/following_table_sp.csv',index=False)\n",
    "followers_table.to_csv('C:/Users/codnj/python_vscode/followers_table_sp.csv',index=False)\n",
    "sample_members_df = pd.DataFrame(sample_members, columns = ['user_name'])\n",
    "sample_members_df['user_url'] = user_urls\n",
    "sample_members_df = sample_members_df.drop_duplicates(['user_name','user_url'],keep='first')\n",
    "\n",
    "sample_members_df['user_id'] = sample_members_df.index\n",
    "sample_members_df = sample_members_df[['user_id','user_name','user_url']]\n",
    "\n",
    "sample_members_df.to_csv('C:/Users/codnj/python_vscode/user_table_sp.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "a_df = pd.DataFrame()\n",
    "\n",
    "print(a_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/profile/cascode', '/profile/pbmichiganwolverine', '/profile/scott_e', '/profile/ctbeck11', '/profile/soonershrink', '/profile/stephanie_moreno', '/profile/washeewashee', '/profile/exelixi', '/profile/thewhiskeyjug', '/profile/joeparkerpoe', '/profile/leeevolved', '/profile/slainte-mhath', '/profile/doneeb', '/profile/islay_emissary', '/profile/richard-moderndrinking']\n"
     ]
    }
   ],
   "source": [
    "f = ['cascode', 'pbmichiganwolverine', 'scott_e', 'ctbeck11', 'soonershrink', 'stephanie_moreno','washeewashee', 'exelixi', 'thewhiskeyjug', 'joeparkerpoe', 'leeevolved', 'slainte-mhath', 'doneeb', 'islay_emissary', 'richard-moderndrinking']\n",
    "list = []                 \n",
    "for i in f:\n",
    "    list.append(\"/profile/\"+i)\n",
    "\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tb = []\n",
    "\n",
    "cnt = 0\n",
    "for i in user_list:\n",
    "\n",
    "    user_url = f'https://distiller.com{i}/tastes'\n",
    "\n",
    "    user_page = requests.get(user_url)\n",
    "    soup = BeautifulSoup(user_page.text ,\"lxml\")\n",
    "    user_name = soup.find('p', attrs={'class':'tertiary-headline name'}).get_text().split()[0]\n",
    "    taste_cnt = soup.find('div', attrs={'class':'statistic tastes-link'}).get_text().split()[0]\n",
    "    follower_cnt = soup.find('div', attrs={'class':'statistic followers-link'}).get_text().split()[0]\n",
    "    following_cnt = soup.find('div', attrs={'class':'statistic following-link'}).get_text().split()[0]\n",
    "    cnt += 1\n",
    "    user_row = [cnt, user_name, user_url, taste_cnt, follower_cnt, following_cnt]\n",
    "    user_tb.append(user_row)\n",
    "\n",
    "print(user_tb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "user_names_df = pd.read_csv(\"./user_table.csv\")\n",
    "user_list = user_names_df['user_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.DataFrame(user_tb, columns=['user_id', 'user_name','user_url','taste_cnt', 'follower_cnt','following_cnt'])\n",
    "\n",
    "user_df.to_csv(\"./user_tb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "user_df = pd.read_csv(\"./user_tb.csv\", names = ['user_id', 'user_id1', 'user_name', 'user_url', 'taste_cnt', 'follower_cnt','following_cnt'], header=0)\n",
    "\n",
    "user_df.drop('user_id1', axis=1, inplace=True)\n",
    "\n",
    "user_url = user_df['user_url']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_url = [i.replace(\"/tastes\", \"\") for i in user_df['user_url']]\n",
    "\n",
    "user_df['user_url']= user_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.to_csv(\"./user_tb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "sul_url = ['https://distiller.com/spirits/jack-daniel-s-single-barrel-coy-hill-high-proof-2021-release', 'https://distiller.com/spirits/ezra-brooks-kentucky-straight-bourbon-99-proof']\n",
    "for i in sul_url:\n",
    "    sul_page = requests.get(i)\n",
    "\n",
    "    sul_page_soup = BeautifulSoup(sul_page.text, 'lxml')\n",
    "    alcohol_cost = str(sul_page_soup.find_all(\"div\", attrs={\"class\": \"spirit-cost\"}))[30:31]\n",
    "    print(str(alcohol_cost))\n",
    "    print(alcohol_cost)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c65b98e956c6ae24f8ae0bc56d1e465ff92310dbdec0a4bd6b48ffdf1441c98"
  },
  "kernelspec": {
   "display_name": "Python 3.6.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
